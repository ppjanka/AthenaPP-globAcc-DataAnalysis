{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "import pickle as pkl\n",
    "import os.path\n",
    "\n",
    "exec(open(\"./diagnostics_header.py\").read())\n",
    "import diagnostics_ops as diops\n",
    "import diagnostics_vars as divars\n",
    "import diagnostics_vis as divis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Porb = 2.*np.pi\n",
    "tstart_steady = {5.:(7.5*Porb), 10.:(34.*Porb)} # sim.u.\n",
    "\n",
    "# time limits of accretion states\n",
    "#accretion_state_times = {10.:{'A':[15.5, 18.], 'B':[18., 20.5], 'C':[20.5, 23.5], 'D':[23.5,27.], 'E':[27.,29.]}, 5.:{}} # Porb\n",
    "accretion_state_times = {10.:{'A':[34.,39.], 'B':[39., 45.6]}, 5.:{}} # Porb\n",
    "\n",
    "# average disk height to average over for equatorial and radial profile s\n",
    "# [as theta in units of 1/mach_no ~ thermal scale height]\n",
    "Havg = 0.5 # just the equator zone (zone 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which machine we're running on\n",
    "import socket\n",
    "machine = socket.gethostname()\n",
    "\n",
    "# list of tasks to perform in the run\n",
    "tasks = {}; tasks['1D'] = []; tasks['2D'] = []; tasks['3D'] = []\n",
    "\n",
    "# parse input\n",
    "import sys\n",
    "if machine == 'ppjanka-razer':\n",
    "    if False:\n",
    "        supfolder = 'M5/R4_32_dfloor1e-6_vfloorRho1e-5'\n",
    "        mach_no = 5\n",
    "    else:\n",
    "        supfolder = 'M10_noInfl/R5_4b_lowDfloor/R5_dfloor1e-6_vfloorRho1e-5'\n",
    "        mach_no = 10\n",
    "else:\n",
    "    supfolder = sys.argv[1]\n",
    "    i = 2\n",
    "    while i < len(sys.argv):\n",
    "        if sys.argv[i] == '-2D':\n",
    "            tasks['2D'].append(sys.argv[i+1])\n",
    "            i += 2\n",
    "        elif sys.argv[i] == '-1D':\n",
    "            tasks['1D'].append(sys.argv[i+1])\n",
    "            i += 2\n",
    "        elif sys.argv[i] == '-3D':\n",
    "            tasks['3D'].append(sys.argv[i+1])\n",
    "            i += 2\n",
    "            \n",
    "# default: perform all tasks, WARNING: this can take a long time\n",
    "if len(tasks['1D']) == 0 and len(tasks['2D']) == 0 and len(tasks['3D']) == 0:\n",
    "     # 2D profile tasks\n",
    "    tasks['2D'] = ['alphaR', 'alphaM', 'rho', 'beta', 'B2_over_B1', 'B3_over_B1', 'B2_over_B3', 'alphaRslices', 'vr', 'vrSlices', 'vel3Slices', 'rhoSlices', 'csoundSlices', 'butterfly', 'butterfly_noAvg', 'butterfly2', 'patternSpeed']\n",
    "    # 1D profile tasks\n",
    "    tasks['1D'] = ['radial', 'vertical'] # 'poloidal'\n",
    "    tasks['3D'] = ['rho', 'csound', 'bfield', 'vertical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on RAZER. Mach number: 10.000000.\n"
     ]
    }
   ],
   "source": [
    "if machine[:7] == 'perseus':\n",
    "    machine = 'PERSEUS'\n",
    "    data_pathstem = '/home/ppjanka/tigress_pp/THESIS/%s/' % supfolder\n",
    "elif machine[:11] == 'tigressdata':\n",
    "    machine = 'TIGRESSDATA'\n",
    "    data_pathstem = '/home/ppjanka/tigress_pp/THESIS/%s/' % supfolder\n",
    "elif machine == 'ppjanka-razer':\n",
    "    machine = 'RAZER'\n",
    "    data_pathstem = '/DATA/Dropbox/LOOTRPV/astro_projects/2017_globAcc1/athena/bin-mhd/%s/' % supfolder\n",
    "\n",
    "if machine != 'RAZER':\n",
    "    mach_no = float(data_pathstem.split('/')[-2].split('M')[1].split('_')[0])\n",
    "    \n",
    "print('Running on %s. Mach number: %f.' % (machine, mach_no))\n",
    "\n",
    "data_folders = ['R4','R5']\n",
    "\n",
    "# ----------\n",
    "import glob\n",
    "\n",
    "athdf_files = []\n",
    "for data_folder in data_folders:\n",
    "    athdf_files += glob.glob(data_pathstem + data_folder + '/*out2*.athdf')\n",
    "athdf_files = sorted(athdf_files)\n",
    "\n",
    "def state2title (acc_state):\n",
    "    if acc_state == None:\n",
    "        return 'steady'\n",
    "    else:\n",
    "        return 'state%s' % acc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profiles_2D (vars_obj, acc_state=None):\n",
    "\n",
    "    # these will hold the final results\n",
    "    ops_obj_eq = None \n",
    "    ops_obj_pol = None\n",
    "\n",
    "    navg_eq = 0; navg_pol = 0\n",
    "    for athdf_file in athdf_files:\n",
    "        print('Processing %s.. ' % athdf_file.split('/')[-1], end='', flush=True)\n",
    "\n",
    "        if (acc_state == None and diops.get_time(athdf_file) > tstart_steady[mach_no]) or (acc_state != None and diops.get_time(athdf_file) > accretion_state_times[mach_no][acc_state][0]*Porb and diops.get_time(athdf_file) < accretion_state_times[mach_no][acc_state][1]*Porb):\n",
    "            # equatorial profile\n",
    "            buff_obj_eq = diops.Profile_PhiR(vars_obj, \\\n",
    "                    x2min=0.5*np.pi-Havg/mach_no, \\\n",
    "                    x2max=0.5*np.pi+Havg/mach_no)\n",
    "            buff_obj_eq.read(athdf_file)\n",
    "            if ops_obj_eq == None:\n",
    "                ops_obj_eq = cp.deepcopy(buff_obj_eq)\n",
    "                ops_obj_eq.time = tstart_steady[mach_no]\n",
    "                navg_eq += 1\n",
    "            else:\n",
    "                if (buff_obj_eq.phi == ops_obj_eq.phi).all() and (buff_obj_eq.r == ops_obj_eq.r).all():\n",
    "                    ops_obj_eq.val += buff_obj_eq.val\n",
    "                    navg_eq += 1\n",
    "                else:\n",
    "                    print('Eq. mesh doesn\\'t match for %s. Ignored.' % athdf_file.split('/')[-1])\n",
    "\n",
    "            # poloidal profile\n",
    "            buff_obj_pol = diops.Profile_ThetaR(vars_obj)\n",
    "            buff_obj_pol.read(athdf_file)\n",
    "            if ops_obj_pol == None:\n",
    "                ops_obj_pol = cp.deepcopy(buff_obj_pol)\n",
    "                ops_obj_pol.time = tstart_steady[mach_no]\n",
    "                navg_pol += 1\n",
    "            else:\n",
    "                if (buff_obj_pol.theta == ops_obj_pol.theta).all() and (buff_obj_pol.r == ops_obj_pol.r).all():\n",
    "                    ops_obj_pol.val += buff_obj_pol.val\n",
    "                    navg_pol += 1\n",
    "                else:\n",
    "                    print('Pol. mesh doesn\\'t match for %s. Ignored.' % athdf_file.split('/')[-1])\n",
    "        else:\n",
    "            print('frame outside the requested time range. ', end='', flush=True)\n",
    "        print('done.', flush=True)\n",
    "\n",
    "    ops_obj_eq.val /= navg_eq\n",
    "    ops_obj_pol.val /= navg_pol\n",
    "\n",
    "    print('\\nDONE.\\n', flush=True)\n",
    "    \n",
    "    return ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'alphaR' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_AlphaReynolds.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # alpha_Reynolds averaged throughout the steady state\n",
    "        vars_obj = divars.AlphaReynolds()\n",
    "        ops_obj_eq, ops_obj_pol = profiles_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "        \n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'alphaM' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_AlphaMaxwell.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # alpha_Maxwell averaged throughout the steady state\n",
    "        vars_obj = divars.AlphaMaxwell()\n",
    "        ops_obj_eq, ops_obj_pol = profiles_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "\n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'rho' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_rho.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('rho')\n",
    "        ops_obj_eq, ops_obj_pol = profiles_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "\n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'vr' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_vr.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('vel1')\n",
    "        ops_obj_eq, ops_obj_pol = profiles_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "\n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'beta' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_PlasmaBeta.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # plasma beta averaged throughout the steady state\n",
    "        vars_obj = divars.PlasmaBeta()\n",
    "        ops_obj_eq, ops_obj_pol = profiles_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "\n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'B2_over_B1' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_B2_over_B1.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        vars_obj = divars.B2_over_B1()\n",
    "        ops_obj_eq, ops_obj_pol = profiles_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "\n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'B3_over_B1' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_B3_over_B1.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        vars_obj = divars.B3_over_B1()\n",
    "        ops_obj_eq, ops_obj_pol = profiles_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "\n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'B2_over_B3' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_B2_over_B3.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        vars_obj = divars.B2_over_B3()\n",
    "        ops_obj_eq, ops_obj_pol = profiles_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "\n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slices_2D (vars_obj, n_poloidal=0, acc_state=None):\n",
    "\n",
    "    # these will hold the final results\n",
    "    ops_obj_eq = None\n",
    "    navg_eq = 0\n",
    "    if n_poloidal > 0:\n",
    "        ops_obj_pol = n_poloidal * [None,]\n",
    "        navg_pol = n_poloidal * [0,]\n",
    "    else:\n",
    "        ops_obj_pol = None\n",
    "        navg_pol = None\n",
    "\n",
    "    for athdf_file in athdf_files:\n",
    "        print('Processing %s.. ' % athdf_file.split('/')[-1], end='', flush=True)\n",
    "\n",
    "        if (acc_state == None and diops.get_time(athdf_file) > tstart_steady[mach_no]) or (acc_state != None and diops.get_time(athdf_file) > accretion_state_times[mach_no][acc_state][0]*Porb and diops.get_time(athdf_file) < accretion_state_times[mach_no][acc_state][1]*Porb):\n",
    "            \n",
    "            # equatorial slice\n",
    "            buff_obj_eq = diops.EquatorialSlice(vars_obj)\n",
    "            buff_obj_eq.read(athdf_file)\n",
    "            if ops_obj_eq == None:\n",
    "                ops_obj_eq = cp.deepcopy(buff_obj_eq)\n",
    "                ops_obj_eq.time = tstart_steady[mach_no]\n",
    "                navg_eq += 1\n",
    "            else:\n",
    "                if (buff_obj_eq.phi == ops_obj_eq.phi).all() and (buff_obj_eq.r == ops_obj_eq.r).all():\n",
    "                    ops_obj_eq.val += buff_obj_eq.val\n",
    "                    navg_eq += 1\n",
    "                else:\n",
    "                    print('Eq. mesh doesn\\'t match for %s. Ignored.' % athdf_file.split('/')[-1])\n",
    "\n",
    "            if n_poloidal > 0:\n",
    "                # poloidal profile\n",
    "                for i in range(n_poloidal):\n",
    "                    buff_obj_pol = diops.PoloidalSlice(vars_obj, intersect=(i*2.*np.pi/n_poloidal+1.0e-3))\n",
    "                    buff_obj_pol.read(athdf_file)\n",
    "                    if ops_obj_pol[i] == None:\n",
    "                        ops_obj_pol[i] = cp.deepcopy(buff_obj_pol)\n",
    "                        ops_obj_pol[i].time = tstart_steady[mach_no]\n",
    "                        navg_pol[i] += 1\n",
    "                    else:\n",
    "                        if (buff_obj_pol.theta == ops_obj_pol[i].theta).all() and (buff_obj_pol.r == ops_obj_pol[i].r).all():\n",
    "                            ops_obj_pol[i].val += buff_obj_pol.val\n",
    "                            navg_pol[i] += 1\n",
    "                        else:\n",
    "                            print('Pol. mesh doesn\\'t match for %s. Ignored.' % athdf_file.split('/')[-1])\n",
    "                            \n",
    "        else:\n",
    "            print('frame outside the requested time range. ', end='', flush=True)\n",
    "        print('done.', flush=True)\n",
    "\n",
    "    ops_obj_eq.val /= navg_eq\n",
    "    for i in range(n_poloidal):\n",
    "        ops_obj_pol[i].val /= navg_pol[i]\n",
    "\n",
    "    print('\\nDONE.\\n', flush=True)\n",
    "    \n",
    "    return ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'alphaRslices' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_AlphaReynoldsSlices.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # alpha_Reynolds averaged throughout the steady state\n",
    "        vars_obj = divars.AlphaReynolds()\n",
    "        ops_obj_eq, ops_obj_pol = slices_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "        \n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'vrSlices' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_vrSlices.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # alpha_Reynolds averaged throughout the steady state\n",
    "        vars_obj = divars.Default('vel1')\n",
    "        ops_obj_eq, ops_obj_pol = slices_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "        \n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'vel3Slices' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_vel3Slices.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # alpha_Reynolds averaged throughout the steady state\n",
    "        vars_obj = divars.Default('vel3')\n",
    "        ops_obj_eq, ops_obj_pol = slices_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "        \n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'rhoSlices' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_rhoSlices.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # alpha_Reynolds averaged throughout the steady state\n",
    "        vars_obj = divars.Default('rho')\n",
    "        ops_obj_eq, ops_obj_pol = slices_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "        \n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'csoundSlices' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_csoundSlices.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # alpha_Reynolds averaged throughout the steady state\n",
    "        vars_obj = divars.Csound()\n",
    "        ops_obj_eq, ops_obj_pol = slices_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "        \n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'bfieldSlices' in tasks['2D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_bfieldSlices.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # alpha_Reynolds averaged throughout the steady state\n",
    "        vars_obj = divars.Bfield()\n",
    "        ops_obj_eq, ops_obj_pol = slices_2D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump((ops_obj_eq, ops_obj_pol), f)\n",
    "        \n",
    "        del vars_obj, ops_obj_eq, ops_obj_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullAvg_3D (vars_obj, acc_state=None):\n",
    "\n",
    "    # these will hold the final results\n",
    "    ops_obj = None\n",
    "\n",
    "    navg = 0\n",
    "    for athdf_file in athdf_files:\n",
    "        print('Processing %s.. ' % athdf_file.split('/')[-1], end='', flush=True)\n",
    "\n",
    "        if (acc_state == None and diops.get_time(athdf_file) > tstart_steady[mach_no]) or (acc_state != None and diops.get_time(athdf_file) > accretion_state_times[mach_no][acc_state][0]*Porb and diops.get_time(athdf_file) < accretion_state_times[mach_no][acc_state][1]*Porb):\n",
    "            \n",
    "            buff_obj = diops.Full3D(vars_obj)\n",
    "            buff_obj.read(athdf_file)\n",
    "            if ops_obj == None:\n",
    "                ops_obj = cp.deepcopy(buff_obj)\n",
    "                ops_obj.time = tstart_steady[mach_no]\n",
    "                navg += 1\n",
    "            else:\n",
    "                ops_obj.val += buff_obj.val\n",
    "                navg += 1\n",
    "\n",
    "        else:\n",
    "            print('frame outside the requested time range. ', end='', flush=True)\n",
    "        print('done.', flush=True)\n",
    "\n",
    "    ops_obj.val /= navg\n",
    "\n",
    "    print('\\nDONE.\\n', flush=True)\n",
    "    \n",
    "    return ops_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'rho' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_rho3D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('rho')\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'vel1' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_vel13D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('vel1')\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj\n",
    "        \n",
    "if 'vel2' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_vel23D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('vel2')\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj\n",
    "        \n",
    "if 'vel3' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_vel33D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('vel3')\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute values of magnetic field components (used for lambda_MRI)\n",
    "if 'absBcc1' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_absBcc13D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('absBcc1')\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj\n",
    "        \n",
    "if 'absBcc2' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_absBcc23D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('absBcc2')\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj\n",
    "        \n",
    "if 'absBcc3' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_absBcc33D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Default('absBcc3')\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'csound' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_csound3D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Csound()\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'bfield' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_bfield3D.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "        \n",
    "        # rho averaged throughout the steady state\n",
    "        vars_obj = divars.Bfield()\n",
    "        ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)\n",
    "\n",
    "        del vars_obj, ops_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_profiles_1D (vars_objs, straddle=None, \\\n",
    "                        x2min=0.5*np.pi-Havg/mach_no, \\\n",
    "                        x2max=0.5*np.pi+Havg/mach_no, \\\n",
    "                        ops_kwargs={}, acc_state=None):\n",
    "\n",
    "    # these will hold the final results\n",
    "    ops_objs = {}\n",
    "\n",
    "    navg = {}\n",
    "    for athdf_file in athdf_files:\n",
    "        print('Processing %s.. ' % athdf_file.split('/')[-1], end='', flush=True)\n",
    "\n",
    "        if (acc_state == None and diops.get_time(athdf_file) > tstart_steady[mach_no]) or (acc_state != None and diops.get_time(athdf_file) > accretion_state_times[mach_no][acc_state][0]*Porb and diops.get_time(athdf_file) < accretion_state_times[mach_no][acc_state][1]*Porb):\n",
    "            for vars_obj in vars_objs:\n",
    "                label = vars_obj.label\n",
    "                if label in ops_kwargs.keys():\n",
    "                    kwargs = ops_kwargs[label]\n",
    "                else:\n",
    "                    kwargs = {}\n",
    "                if straddle == None:\n",
    "                    buff_obj = diops.RadialProfile(vars_obj, \\\n",
    "                        x2min=x2min, \\\n",
    "                        x2max=x2max, \\\n",
    "                        **kwargs)\n",
    "                else:\n",
    "                    buff_obj = diops.RadialProfile_Straddle(vars_obj, \\\n",
    "                        x2min=straddle[0], \\\n",
    "                        x2max=straddle[1], \\\n",
    "                        **kwargs)\n",
    "                buff_obj.read(athdf_file)\n",
    "                if label not in ops_objs.keys():\n",
    "                    ops_objs[label] = cp.deepcopy(buff_obj)\n",
    "                    ops_objs[label].time = tstart_steady\n",
    "                    navg[label] = 1\n",
    "                else:\n",
    "                    if (buff_obj.r == ops_objs[label].r).all():\n",
    "                        ops_objs[label].val += buff_obj.val\n",
    "                        navg[label] += 1\n",
    "                    else:\n",
    "                        print('Mesh doesn\\'t match for %s, label %s. Ignored.' % (athdf_file.split('/')[-1], label))\n",
    "                    \n",
    "        else:\n",
    "            print('frame outside the requested time range. ', end='', flush=True)\n",
    "        print('done.', flush=True)\n",
    "\n",
    "    for label in ops_objs.keys():\n",
    "        ops_objs[label].val /= navg[label]\n",
    "\n",
    "    print('\\nDONE.\\n', flush=True)\n",
    "    \n",
    "    return ops_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'radial' in tasks['1D']:\n",
    "    # read the 1D profiles\n",
    "    if mach_no == 5.:\n",
    "        sup_kwargs = [{'x2min':0.5*np.pi-2.5/mach_no, \\\n",
    "                       'x2max':0.5*np.pi+2.5/mach_no}, \\\n",
    "                      {'straddle':(0.5*np.pi-5.0/mach_no, \\\n",
    "                                   0.5*np.pi-2.5/mach_no)}]\n",
    "    elif mach_no == 10.:\n",
    "        sup_kwargs = [{'x2min':0.5*np.pi-2./mach_no, \\\n",
    "                       'x2max':0.5*np.pi+2./mach_no}, \\\n",
    "                      {'straddle':(0.5*np.pi-10./mach_no, \\\n",
    "                                   0.5*np.pi-2./mach_no)}]\n",
    "\n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_radial.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "            \n",
    "        ops_objs = {}\n",
    "        ops_objs['sup_kwargs'] = sup_kwargs\n",
    "            \n",
    "        for idx in range(len(sup_kwargs)):\n",
    "            ops_objs[idx] = radial_profiles_1D([divars.Default('rho'),\n",
    "                               divars.PressMag(), divars.Default('press'),\n",
    "                               divars.Mdot(),\n",
    "                               divars.AlphaReynolds(), divars.AlphaMaxwell()],\n",
    "                               ops_kwargs={'rho':{'type':'surface_density'}, 'Mdot':{'type':'sum'}}, \n",
    "                                **(sup_kwargs[idx]), acc_state=acc_state)\n",
    "            ops_objs[idx]['Ptot'] = cp.deepcopy(ops_objs[idx]['press'])\n",
    "            ops_objs[idx]['Ptot'].val += ops_objs[idx]['Pmag'].val\n",
    "            ops_objs[idx]['alpha_tot'] = cp.deepcopy(ops_objs[idx]['alpha_Reynolds'])\n",
    "            ops_objs[idx]['alpha_tot'].val += ops_objs[idx]['alpha_Maxwell'].val\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_objs, f)\n",
    "            \n",
    "        del ops_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poloidal_profiles_1D (vars_objs, radii, ops_kwargs={}, acc_state=None):\n",
    "\n",
    "    # these will hold the final results\n",
    "    ops_objs = {}\n",
    "\n",
    "    navg = {}\n",
    "    for athdf_file in athdf_files:\n",
    "        print('Processing %s.. ' % athdf_file.split('/')[-1], end='', flush=True)\n",
    "\n",
    "        if (acc_state == None and diops.get_time(athdf_file) > tstart_steady[mach_no]) or (acc_state != None and diops.get_time(athdf_file) > accretion_state_times[mach_no][acc_state][0]*Porb and diops.get_time(athdf_file) < accretion_state_times[mach_no][acc_state][1]*Porb):\n",
    "            for vars_obj in vars_objs:\n",
    "                label = vars_obj.label\n",
    "                if label in ops_kwargs.keys():\n",
    "                    kwargs = ops_kwargs[label]\n",
    "                else:\n",
    "                    kwargs = {}\n",
    "                if label not in ops_objs.keys():\n",
    "                    ops_objs[label] = {}\n",
    "                    navg[label] = {}\n",
    "                for radius in radii:\n",
    "                    buff_obj = {}\n",
    "                    buff_obj['slice'] = diops.Profile_Theta(vars_obj, \\\n",
    "                            x1min=radius, x1max=radius, \\\n",
    "                            x3min=np.pi, x3max=np.pi, \\\n",
    "                            **kwargs)\n",
    "                    buff_obj['avg'] = diops.Profile_Theta(vars_obj, \\\n",
    "                            x1min=radius, x1max=radius, \\\n",
    "                            **kwargs)\n",
    "                    for t in ['slice', 'avg']:\n",
    "                        buff_obj[t].read(athdf_file)\n",
    "                    if radius not in ops_objs[label].keys():\n",
    "                        ops_objs[label][radius] = {}\n",
    "                        navg[label][radius] = {}\n",
    "                        for t in ['slice', 'avg']:\n",
    "                            ops_objs[label][radius][t] = cp.deepcopy(buff_obj[t])\n",
    "                            ops_objs[label][radius][t].time = tstart_steady[mach_no]\n",
    "                            navg[label][radius][t] = 1\n",
    "                    else:\n",
    "                        for t in ['slice', 'avg']:\n",
    "                            if (buff_obj[t].theta == ops_objs[label][radius][t].theta).all():\n",
    "                                ops_objs[label][radius][t].val += buff_obj[t].val\n",
    "                                navg[label][radius][t] += 1\n",
    "                            else:\n",
    "                                print('Mesh doesn\\'t match for %s, label %s, radius %f, type %s. Ignored.' % (athdf_file.split('/')[-1], label, radius, t))\n",
    "                    \n",
    "        else:\n",
    "            print('frame outside the requested time range. ', end='', flush=True)\n",
    "        print('done.', flush=True)\n",
    "\n",
    "    for label in ops_objs.keys():\n",
    "        for radius in ops_objs[label].keys():\n",
    "            for t in ops_objs[label][radius].keys():\n",
    "                ops_objs[label][radius][t].val /= navg[label][radius][t]\n",
    "\n",
    "    print('\\nDONE.\\n', flush=True)\n",
    "    \n",
    "    return ops_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'poloidal' in tasks['1D']:\n",
    "    \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        outfile = data_pathstem + ('%s_poloidal.pkl' % state2title(acc_state))\n",
    "        \n",
    "        if os.path.isfile(outfile): continue\n",
    "\n",
    "        # read the 1D profiles\n",
    "        ops_objs_poloidal = poloidal_profiles_1D([divars.Default('rho'),\n",
    "                           divars.PressMag(), divars.Default('press'),\n",
    "                           divars.Mdot(),\n",
    "                           divars.AlphaReynolds(),\n",
    "                           divars.AlphaMaxwell(),\n",
    "                           divars.StressMaxwell(),\n",
    "                           divars.StressReynolds()],\n",
    "                    radii=[0.06, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "                    ops_kwargs={'Mdot':{'type':'sum'}}, acc_state=acc_state)\n",
    "\n",
    "        ops_objs_poloidal['Ptot'] = {}\n",
    "        ops_objs_poloidal['alpha_tot'] = {}\n",
    "        for radius in ops_objs_poloidal['rho'].keys():\n",
    "            ops_objs_poloidal['Ptot'][radius] = {}\n",
    "            ops_objs_poloidal['alpha_tot'][radius] = {}\n",
    "            for t in ops_objs_poloidal['rho'][radius].keys():\n",
    "                ops_objs_poloidal['Ptot'][radius][t] = cp.deepcopy(ops_objs_poloidal['press'][radius][t])\n",
    "                ops_objs_poloidal['Ptot'][radius][t].val += ops_objs_poloidal['Pmag'][radius][t].val\n",
    "                ops_objs_poloidal['alpha_tot'][radius][t] = cp.deepcopy(ops_objs_poloidal['alpha_Reynolds'][radius][t])\n",
    "                ops_objs_poloidal['alpha_tot'][radius][t].val += ops_objs_poloidal['alpha_Maxwell'][radius][t].val\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_objs_poloidal, f)\n",
    "            \n",
    "        del ops_objs_poloidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_profiles_1D (vars_objs, radii, x2min=0.1, x2max=(np.pi-0.1), ops_kwargs={}, acc_states=[None,]):\n",
    "\n",
    "    # these will hold the final results, initialize\n",
    "    ops_objs = {}\n",
    "    navg = {}\n",
    "    for acc_state in acc_states:\n",
    "        ops_objs[acc_state] = {}\n",
    "        navg[acc_state] = {}\n",
    "        for vars_obj in vars_objs:\n",
    "            label = vars_obj.label\n",
    "            if label not in ops_objs[acc_state].keys():\n",
    "                ops_objs[acc_state][label] = {}\n",
    "                navg[acc_state][label] = {}\n",
    "                for t in ['slice', 'avg']:\n",
    "                    navg[acc_state][label][t] = {}\n",
    "                    for radius in radii:\n",
    "                        navg[acc_state][label][t][radius] = 1\n",
    "            if label not in ops_kwargs.keys():\n",
    "                ops_kwargs[label] = {}\n",
    "            \n",
    "    # ------------------------------------\n",
    "    \n",
    "    for athdf_file in athdf_files:\n",
    "        \n",
    "        print('Processing %s.. ' % athdf_file.split('/')[-1], flush=True)\n",
    "        \n",
    "        # ignore if not in any accretion state\n",
    "        calculate = False\n",
    "        for acc_state in acc_states:\n",
    "            if (acc_state == None and diops.get_time(athdf_file) > tstart_steady[mach_no]) or (acc_state != None and diops.get_time(athdf_file) > accretion_state_times[mach_no][acc_state][0]*Porb and diops.get_time(athdf_file) < accretion_state_times[mach_no][acc_state][1]*Porb):\n",
    "                calculate = True\n",
    "                break\n",
    "        if not calculate:\n",
    "            print('      > frame outside any of the requested time ranges. ', flush=True)\n",
    "            continue\n",
    "\n",
    "        # calculate the profiles\n",
    "        for vars_obj in vars_objs:\n",
    "\n",
    "            label = vars_obj.label\n",
    "            print(' - %s.. ' % label, flush=True)\n",
    "\n",
    "            kwargs = ops_kwargs[label]\n",
    "\n",
    "            buff_obj = {}\n",
    "            buff_obj['slice'] = \\\n",
    "                diops.Profile_Cyl_Vertical(vars_obj, radii, \\\n",
    "                    x2min=x2min, x2max=x2max,\\\n",
    "                    x3min=np.pi, x3max=np.pi,\\\n",
    "                    nproc=nproc, **kwargs)\n",
    "            buff_obj['avg'] = \\\n",
    "                diops.Profile_Cyl_Vertical(vars_obj, radii,\\\n",
    "                    x2min=x2min, x2max=x2max,\\\n",
    "                    nproc=nproc, **kwargs)\n",
    "\n",
    "            for t in ['slice', 'avg']:\n",
    "                buff_obj[t].read(athdf_file)\n",
    "        \n",
    "            for acc_state in acc_states:\n",
    "\n",
    "                print('   - state %s' % acc_state, flush=True)\n",
    "\n",
    "                if (acc_state == None and diops.get_time(athdf_file) > tstart_steady[mach_no]) or (acc_state != None and diops.get_time(athdf_file) > accretion_state_times[mach_no][acc_state][0]*Porb and diops.get_time(athdf_file) < accretion_state_times[mach_no][acc_state][1]*Porb):\n",
    "\n",
    "                    if len(ops_objs[acc_state][label].keys()) == 0:\n",
    "                        ops_objs[acc_state][label] = cp.deepcopy(buff_obj)\n",
    "                    else:\n",
    "                        for t in ['slice', 'avg']:\n",
    "                            for radius in radii:\n",
    "                                ops_objs[acc_state][label][t].val[radius] += buff_obj[t].val[radius]\n",
    "                                navg[acc_state][label][t][radius] += 1\n",
    "  \n",
    "                    print('      done.', flush=True)\n",
    "\n",
    "                else:\n",
    "                    print('      > frame outside the requested time range. ', flush=True)\n",
    "                \n",
    "            # clean up\n",
    "            del buff_obj\n",
    "        \n",
    "    for acc_state in acc_states:\n",
    "\n",
    "        for label in ops_objs[acc_state].keys():\n",
    "            for t in ops_objs[acc_state][label].keys():\n",
    "                for radius in ops_objs[acc_state][label][t].val.keys():\n",
    "                    ops_objs[acc_state][label][t].val[radius] /= navg[acc_state][label][t][radius]\n",
    "\n",
    "    print('\\nDONE.\\n', flush=True)\n",
    "\n",
    "    return ops_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'vertical' in tasks['1D']:\n",
    "    \n",
    "    acc_states = []\n",
    "    outfiles = {}\n",
    "    for acc_state in list(accretion_state_times[mach_no].keys()) + [None,]:\n",
    "        outfiles[acc_state] = data_pathstem + ('%s_vertical.pkl' % state2title(acc_state))\n",
    "        if not os.path.isfile(outfiles[acc_state]):\n",
    "            acc_states.append(acc_state)\n",
    "            \n",
    "    if mach_no == 5.:\n",
    "        x2min = 0.5*np.pi - 5./mach_no\n",
    "        x2max = 0.5*np.pi + 5./mach_no\n",
    "    elif mach_no == 10.:\n",
    "        x2min = 0.5*np.pi - 10./mach_no\n",
    "        x2max = 0.5*np.pi + 10./mach_no\n",
    "\n",
    "    # read the 1D profiles\n",
    "    ops_objs_vertical = vertical_profiles_1D([divars.Default('rho'),\n",
    "                           divars.PressMag(), divars.Default('press'),\n",
    "                           divars.Mdot(vertical=True),\n",
    "                           divars.AlphaReynolds(),\n",
    "                           divars.AlphaMaxwell(),\n",
    "                           divars.StressMaxwell(),\n",
    "                           divars.StressReynolds()],\n",
    "                    radii=[0.06, 0.1, 0.15, 0.2, 0.25],\n",
    "                    x2min=x2min, x2max=x2max,\n",
    "                    ops_kwargs={'Mdot':{'type':'sum'}},\n",
    "                    acc_states=acc_states)\n",
    "\n",
    "    for acc_state in acc_states:\n",
    "    \n",
    "        ops_objs_vertical[acc_state]['Ptot'] = {}\n",
    "        ops_objs_vertical[acc_state]['alpha_tot'] = {}\n",
    "\n",
    "        for t in ops_objs_vertical[acc_state]['rho'].keys():\n",
    "            ops_objs_vertical[acc_state]['Ptot'][t] = cp.deepcopy(ops_objs_vertical[acc_state]['press'][t])\n",
    "            ops_objs_vertical[acc_state]['alpha_tot'][t] = cp.deepcopy(ops_objs_vertical[acc_state]['alpha_Reynolds'][t])\n",
    "            for radius in ops_objs_vertical[acc_state]['rho'][t].radii:\n",
    "                ops_objs_vertical[acc_state]['Ptot'][t].val[radius] += ops_objs_vertical[acc_state]['Pmag'][t].val[radius]\n",
    "                ops_objs_vertical[acc_state]['alpha_tot'][t].val[radius] += ops_objs_vertical[acc_state]['alpha_Maxwell'][t].val[radius]\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfiles[acc_state], 'wb') as f:\n",
    "            pkl.dump(ops_objs_vertical[acc_state], f)\n",
    "            \n",
    "        del ops_objs_vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'vertical' in tasks['3D']:\n",
    "        \n",
    "    for acc_state in [None,]+list(accretion_state_times[mach_no].keys()):\n",
    "        \n",
    "        print('ACCRETION STATE: %s' % state2title(acc_state), flush=True)\n",
    "    \n",
    "        for vars_obj in [divars.Default('rho'),\n",
    "                           divars.PressMag(), divars.Default('press'),\n",
    "                           divars.Mdot(vertical=True),\n",
    "                           divars.AlphaReynolds(),\n",
    "                           divars.AlphaMaxwell(),\n",
    "                           divars.StressMaxwell(),\n",
    "                           divars.StressReynolds()]:\n",
    "            \n",
    "            print('Processing %s...' % vars_obj.label, flush=True)\n",
    "\n",
    "            outfile = data_pathstem + ('%s_%s3D.pkl' % (state2title(acc_state), vars_obj.label))\n",
    "\n",
    "            if os.path.isfile(outfile):\n",
    "                print(' -- already exists', flush=True)\n",
    "                continue\n",
    "\n",
    "            # averaged throughout the steady state\n",
    "            ops_obj = fullAvg_3D(vars_obj, acc_state=acc_state)\n",
    "\n",
    "            # save for reuse\n",
    "            with open(outfile, 'wb') as f:\n",
    "                pkl.dump(ops_obj, f)\n",
    "\n",
    "            del vars_obj, ops_obj\n",
    "            print(' -- done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_profiles_1D_from3D (vars_objs, radii, ops_kwargs={}, acc_states=[None,]):\n",
    "\n",
    "    # these will hold the final results, initialize\n",
    "    ops_objs = {}\n",
    "    for acc_state in acc_states:\n",
    "        ops_objs[acc_state] = {}\n",
    "        for vars_obj in vars_objs:\n",
    "            label = vars_obj.label\n",
    "            if label not in ops_objs[acc_state].keys():\n",
    "                ops_objs[acc_state][label] = {}\n",
    "            if label not in ops_kwargs.keys():\n",
    "                ops_kwargs[label] = {}\n",
    "            \n",
    "    # ------------------------------------\n",
    "    \n",
    "    for vars_obj in vars_objs:\n",
    "\n",
    "        label = vars_obj.label\n",
    "        print(' - %s.. ' % label, flush=True)\n",
    "        kwargs = ops_kwargs[label]\n",
    "        \n",
    "        for acc_state in acc_states:\n",
    "\n",
    "            print('   - state %s' % acc_state, flush=True)\n",
    "            \n",
    "            outfile = data_pathstem + ('%s_%s3D.pkl' % (state2title(acc_state), vars_obj.label))\n",
    "\n",
    "            if not os.path.isfile(outfile):\n",
    "                print(' -- waiting for file', flush=True)\n",
    "                continue\n",
    "\n",
    "            # load 3D file\n",
    "            with open(outfile, 'rb') as f:\n",
    "                ops_obj_3D = pkl.load(f)\n",
    "\n",
    "            buff_obj = {}\n",
    "            buff_obj['slice'] = \\\n",
    "                diops.Profile_Cyl_Vertical(vars_obj, radii, \\\n",
    "                    x2min=x2min, x2max=x2max,\\\n",
    "                    x3min=np.pi, x3max=np.pi,\\\n",
    "                    nproc=nproc, **kwargs)\n",
    "            buff_obj['avg'] = \\\n",
    "                diops.Profile_Cyl_Vertical(vars_obj, radii,\\\n",
    "                    x2min=x2min, x2max=x2max,\\\n",
    "                    x3min=0., x3max=(2.*np.pi),\\\n",
    "                    nproc=nproc, **kwargs)\n",
    "\n",
    "            for t in ['slice', 'avg']:\n",
    "                buff_obj[t].read_from_3D(ops_obj_3D)\n",
    "\n",
    "            ops_objs[acc_state][label] = cp.deepcopy(buff_obj)\n",
    "    \n",
    "    return ops_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "force_calc = True\n",
    "if 'vertical' in tasks['3D']:\n",
    "    \n",
    "    acc_states = []\n",
    "    outfiles = {}\n",
    "    for acc_state in list(accretion_state_times[mach_no].keys()) + [None,]:\n",
    "        outfiles[acc_state] = data_pathstem + ('%s_vertical.pkl' % state2title(acc_state))\n",
    "        if not os.path.isfile(outfiles[acc_state]) or force_calc:\n",
    "            acc_states.append(acc_state)\n",
    "            \n",
    "    if mach_no == 5.:\n",
    "        x2min = 0.5*np.pi - 5./mach_no\n",
    "        x2max = 0.5*np.pi + 5./mach_no\n",
    "    elif mach_no == 10.:\n",
    "        x2min = 0.5*np.pi - 10./mach_no\n",
    "        x2max = 0.5*np.pi + 10./mach_no\n",
    "\n",
    "    # read the 1D profiles\n",
    "    ops_objs_vertical = vertical_profiles_1D_from3D([divars.Default('rho'),\n",
    "                           divars.PressMag(), divars.Default('press'),\n",
    "                           divars.Mdot(vertical=True),\n",
    "                           divars.AlphaReynolds(), # incorrect avg !\n",
    "                           divars.AlphaMaxwell(), # incorrect avg !\n",
    "                           divars.StressMaxwell(),\n",
    "                           divars.StressReynolds()],\n",
    "                    radii=[0.08, 0.11, 0.15, 0.2, 0.25],\n",
    "                    ops_kwargs={'Mdot':{'type':'sum'}},\n",
    "                    acc_states=acc_states)\n",
    "\n",
    "    for acc_state in acc_states:\n",
    "    \n",
    "        ops_objs_vertical[acc_state]['Ptot'] = {}\n",
    "        ops_objs_vertical[acc_state]['alpha_tot'] = {}\n",
    "\n",
    "        for t in ops_objs_vertical[acc_state]['rho'].keys():\n",
    "            ops_objs_vertical[acc_state]['Ptot'][t] = cp.deepcopy(ops_objs_vertical[acc_state]['press'][t])\n",
    "            ops_objs_vertical[acc_state]['alpha_tot'][t] = cp.deepcopy(ops_objs_vertical[acc_state]['alpha_Reynolds'][t])\n",
    "            for radius in ops_objs_vertical[acc_state]['rho'][t].radii:\n",
    "                ops_objs_vertical[acc_state]['Ptot'][t].val[radius] += ops_objs_vertical[acc_state]['Pmag'][t].val[radius]\n",
    "                ops_objs_vertical[acc_state]['alpha_tot'][t].val[radius] += ops_objs_vertical[acc_state]['alpha_Maxwell'][t].val[radius]\n",
    "\n",
    "        # save for reuse\n",
    "        with open(outfiles[acc_state], 'wb') as f:\n",
    "            pkl.dump(ops_objs_vertical[acc_state], f)\n",
    "\n",
    "    del ops_objs_vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'butterfly' in tasks['2D']:\n",
    "    \n",
    "    z_over_H_max = 6.0\n",
    "    z_over_r_max = z_over_H_max / mach_no\n",
    "    \n",
    "    dx2 = np.arctan(z_over_r_max) + 0.1\n",
    "    \n",
    "    for direction in ['Bcc3', 'Bcc2', 'Bcc1']:\n",
    "        \n",
    "        print('Processing direction %s' % direction)\n",
    "        \n",
    "        outfile = data_pathstem + ('butterfly_%s.pkl' % direction)\n",
    "        \n",
    "        vars_obj = divars.Default(direction)\n",
    "        \n",
    "        # reload if exists\n",
    "        if os.path.isfile(outfile):\n",
    "            with open(outfile, 'rb') as f:\n",
    "                ops_obj = pkl.load(f)\n",
    "        else:\n",
    "            ops_obj = diops.ButterflyDiagram(vars_obj, \\\n",
    "                radii=[0.08, 0.11, 0.15, 0.2, 0.25], \\\n",
    "                x2min=(0.5*np.pi - dx2), x2max=(0.5*np.pi + dx2), \\\n",
    "                nz=1024)\n",
    "        \n",
    "        ops_obj.read(athdf_files, verbose=True, \\\n",
    "                temp_save_path=outfile)\n",
    "        \n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'butterfly_noAvg' in tasks['2D']:\n",
    "    \n",
    "    z_over_H_max = 6.0\n",
    "    z_over_r_max = z_over_H_max / mach_no\n",
    "    \n",
    "    dx2 = np.arctan(z_over_r_max) + 0.1\n",
    "    \n",
    "    for direction in ['Bcc3', 'Bcc2', 'Bcc1']:\n",
    "        \n",
    "        print('Processing direction %s' % direction)\n",
    "        \n",
    "        outfile = data_pathstem + ('butterfly_noAvg_%s.pkl' % direction)\n",
    "        \n",
    "        vars_obj = divars.Default(direction)\n",
    "        \n",
    "        # reload if exists\n",
    "        if os.path.isfile(outfile):\n",
    "            with open(outfile, 'rb') as f:\n",
    "                ops_obj = pkl.load(f)\n",
    "        else:\n",
    "            ops_obj = diops.ButterflyDiagram(vars_obj, \\\n",
    "                radii=[0.08, 0.11, 0.15, 0.2, 0.25], \\\n",
    "                x2min=(0.5*np.pi - dx2), x2max=(0.5*np.pi + dx2), \\\n",
    "                x3min=np.pi, x3max=np.pi, \\\n",
    "                nz=1024)\n",
    "        \n",
    "        ops_obj.read(athdf_files, verbose=True, \\\n",
    "                temp_save_path=outfile)\n",
    "        \n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'butterfly2' in tasks['2D']:\n",
    "    \n",
    "    z_over_H_max = 6.0\n",
    "    z_over_r_max = z_over_H_max / mach_no\n",
    "    \n",
    "    dx2 = np.arctan(z_over_r_max) + 0.1\n",
    "    \n",
    "    for direction in ['KinHelicityRMS','vel3rms']:# ['vel1rms', 'vel2rms', 'vel3rms', 'EMF1','EMF2','EMF3', 'Turb_Ekin']:\n",
    "        \n",
    "        print('Processing direction %s' % direction)\n",
    "        \n",
    "        outfile = data_pathstem + ('butterfly_%s.pkl' % direction)\n",
    "        \n",
    "        avgtype = 'avg'\n",
    "        if direction == 'EMF1':\n",
    "            vars_obj = divars.EMF1()\n",
    "        elif direction == 'EMF2':\n",
    "            vars_obj = divars.EMF2()\n",
    "        elif direction == 'EMF3':\n",
    "            vars_obj = divars.EMF3()\n",
    "        elif direction == 'Turb_Ekin':\n",
    "            vars_obj = divars.TurbKineticEnergy()\n",
    "        elif direction == 'KinHelicityRMS':\n",
    "            vars_obj = divars.KinHelicity(GM=0.7692307692307692, omega=1.0)\n",
    "            avgtype = 'rms'\n",
    "        elif direction in ['vel1rms', 'vel2rms']:\n",
    "            vars_obj = divars.Default(direction[:4])\n",
    "            avgtype = 'rms'\n",
    "        elif direction == 'vel3rms':\n",
    "            vars_obj = divars.Vel3Fluct(GM=0.7692307692307692, omega=1.0)\n",
    "            avgtype = 'rms'\n",
    "        \n",
    "        # reload if exists\n",
    "        if os.path.isfile(outfile):\n",
    "            with open(outfile, 'rb') as f:\n",
    "                ops_obj = pkl.load(f)\n",
    "        else:\n",
    "            ops_obj = diops.ButterflyDiagram(vars_obj, \\\n",
    "                radii=[0.08, 0.11, 0.15, 0.2, 0.25], \\\n",
    "                x2min=(0.5*np.pi - dx2), x2max=(0.5*np.pi + dx2), \\\n",
    "                nz=1024, type=avgtype)\n",
    "        \n",
    "        ops_obj.read(athdf_files, verbose=True, \\\n",
    "                temp_save_path=outfile)\n",
    "        \n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing direction Bcc1\n",
      " - reading mhdLoops_strat.out2.00610.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00611.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00612.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00613.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00614.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00615.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00616.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00617.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00618.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00619.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00620.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00621.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00622.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00623.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00624.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00625.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00626.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00627.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00628.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00629.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00630.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00631.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00632.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00633.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00634.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00635.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00636.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00637.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00638.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00639.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00640.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00641.athdf.. already read. Skipping.\n",
      " - reading mhdLoops_strat.out2.00642.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00643.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00644.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00645.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00646.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00647.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00648.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00649.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00650.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00651.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00652.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00653.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00654.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00655.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00656.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00657.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00658.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00659.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00660.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00661.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00662.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00663.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00664.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00665.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00666.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00667.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00668.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00669.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00670.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00671.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00672.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00673.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00674.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00675.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00676.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00677.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00678.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00679.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00680.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00681.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00682.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00683.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00684.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00685.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00686.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00687.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00688.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00689.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00690.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00691.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00692.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00693.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00694.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00695.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00696.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00697.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00698.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00699.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00700.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00701.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00702.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00703.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00704.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00705.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00706.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00707.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00708.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00709.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00710.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00711.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00712.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00713.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00714.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00715.athdf.. already read. Skipping.\n",
      " - reading mhdLoops_strat.out2.00716.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00717.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00718.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00719.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00720.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00721.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00722.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00723.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00724.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00725.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00726.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00727.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00728.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00729.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00730.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00731.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00732.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00733.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00734.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00735.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00736.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00737.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00738.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00739.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00740.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00741.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00742.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00743.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00744.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00745.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00746.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00747.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00748.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00749.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00750.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00751.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00752.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00753.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00754.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00755.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00756.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00757.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00758.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00759.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00760.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00761.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00762.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00763.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00764.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00765.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00766.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00767.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00768.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00769.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00770.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00771.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00772.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00773.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00774.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00775.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00776.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00777.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00778.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00779.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00780.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00781.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00782.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00783.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00784.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00785.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00786.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00787.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00788.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00789.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00790.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00791.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00792.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00793.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00794.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00795.athdf.. already read. Skipping.\n",
      " - reading mhdLoops_strat.out2.00796.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00797.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00798.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00799.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00800.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00801.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00802.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00803.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00804.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00805.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00806.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00807.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00808.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00809.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00810.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00811.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00812.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00813.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00814.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00815.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00816.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00817.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00818.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00819.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00820.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00821.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00822.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00823.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00824.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00825.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00826.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00827.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00828.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00829.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00830.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00831.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00832.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00833.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00834.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00835.athdf.. already read. Skipping.\n",
      " - reading mhdLoops_strat.out2.00836.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00837.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00838.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00839.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00840.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00841.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00842.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00843.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00844.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00845.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00846.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00847.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00848.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00849.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00850.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00851.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00852.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00853.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00854.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00855.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00856.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00857.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00858.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00859.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00860.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00861.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00862.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00863.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00864.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00865.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00866.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00867.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00868.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00869.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00870.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00871.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00872.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00873.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00874.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00875.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00876.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00877.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00878.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00879.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00880.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00881.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00882.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00883.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00884.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00885.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00886.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00887.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00888.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00889.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00890.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00891.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00892.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00893.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00894.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00895.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00896.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00897.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00898.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00899.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00900.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00901.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00902.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00903.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00904.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00905.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00906.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00907.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00908.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00909.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00910.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00911.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00912.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00913.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00914.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00915.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00916.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00917.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00918.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00919.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00920.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00921.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00922.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00923.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00924.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00925.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00926.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00927.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00928.athdf.. done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - reading mhdLoops_strat.out2.00929.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00930.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00931.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00932.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00933.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00934.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00935.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00936.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00937.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00938.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00939.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00940.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00941.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00942.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00943.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00944.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00945.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00946.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00947.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00948.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00949.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00950.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00951.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00952.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00953.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00954.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00955.athdf.. done.\n",
      "All files read.\n",
      "Processing direction rho\n",
      " - reading mhdLoops_strat.out2.00610.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00611.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00612.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00613.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00614.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00615.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00616.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00617.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00618.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00619.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00620.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00621.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00622.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00623.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00624.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00625.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00626.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00627.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00628.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00629.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00630.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00631.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00632.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00633.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00634.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00635.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00636.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00637.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00638.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00639.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00640.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00641.athdf.. already read. Skipping.\n",
      " - reading mhdLoops_strat.out2.00642.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00643.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00644.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00645.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00646.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00647.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00648.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00649.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00650.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00651.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00652.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00653.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00654.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00655.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00656.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00657.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00658.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00659.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00660.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00661.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00662.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00663.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00664.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00665.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00666.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00667.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00668.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00669.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00670.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00671.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00672.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00673.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00674.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00675.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00676.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00677.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00678.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00679.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00680.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00681.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00682.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00683.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00684.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00685.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00686.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00687.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00688.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00689.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00690.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00691.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00692.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00693.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00694.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00695.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00696.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00697.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00698.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00699.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00700.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00701.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00702.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00703.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00704.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00705.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00706.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00707.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00708.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00709.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00710.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00711.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00712.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00713.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00714.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00715.athdf.. already read. Skipping.\n",
      " - reading mhdLoops_strat.out2.00716.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00717.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00718.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00719.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00720.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00721.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00722.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00723.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00724.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00725.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00726.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00727.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00728.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00729.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00730.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00731.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00732.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00733.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00734.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00735.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00736.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00737.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00738.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00739.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00740.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00741.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00742.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00743.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00744.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00745.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00746.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00747.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00748.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00749.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00750.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00751.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00752.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00753.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00754.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00755.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00756.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00757.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00758.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00759.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00760.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00761.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00762.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00763.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00764.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00765.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00766.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00767.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00768.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00769.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00770.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00771.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00772.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00773.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00774.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00775.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00776.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00777.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00778.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00779.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00780.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00781.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00782.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00783.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00784.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00785.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00786.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00787.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00788.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00789.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00790.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00791.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00792.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00793.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00794.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00795.athdf.. already read. Skipping.\n",
      " - reading mhdLoops_strat.out2.00796.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00797.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00798.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00799.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00800.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00801.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00802.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00803.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00804.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00805.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00806.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00807.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00808.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00809.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00810.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00811.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00812.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00813.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00814.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00815.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00816.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00817.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00818.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00819.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00820.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00821.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00822.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00823.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00824.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00825.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00826.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00827.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00828.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00829.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00830.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00831.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00832.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00833.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00834.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00835.athdf.. already read. Skipping.\n",
      " - reading mhdLoops_strat.out2.00836.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00837.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00838.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00839.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00840.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00841.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00842.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00843.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00844.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00845.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00846.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00847.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00848.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00849.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00850.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00851.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00852.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00853.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00854.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00855.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00856.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00857.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00858.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00859.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00860.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00861.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00862.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00863.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00864.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00865.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00866.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00867.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00868.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00869.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00870.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00871.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00872.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00873.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00874.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00875.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00876.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00877.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00878.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00879.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00880.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00881.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00882.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00883.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00884.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00885.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00886.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00887.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00888.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00889.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00890.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00891.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00892.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00893.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00894.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00895.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00896.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00897.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00898.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00899.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00900.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00901.athdf.. done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - reading mhdLoops_strat.out2.00902.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00903.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00904.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00905.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00906.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00907.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00908.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00909.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00910.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00911.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00912.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00913.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00914.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00915.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00916.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00917.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00918.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00919.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00920.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00921.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00922.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00923.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00924.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00925.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00926.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00927.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00928.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00929.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00930.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00931.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00932.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00933.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00934.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00935.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00936.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00937.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00938.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00939.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00940.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00941.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00942.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00943.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00944.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00945.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00946.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00947.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00948.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00949.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00950.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00951.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00952.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00953.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00954.athdf.. done.\n",
      " - reading mhdLoops_strat.out2.00955.athdf.. done.\n",
      "All files read.\n"
     ]
    }
   ],
   "source": [
    "if 'patternSpeed' in tasks['2D']:\n",
    "    \n",
    "    for direction in ['Bcc1','rho']:\n",
    "        \n",
    "        print('Processing direction %s' % direction)\n",
    "        \n",
    "        outfile = data_pathstem + ('patternSpeed_%s.pkl' % direction)\n",
    "        \n",
    "        vars_obj = divars.Default(direction)\n",
    "        \n",
    "        # reload if exists\n",
    "        if os.path.isfile(outfile):\n",
    "            with open(outfile, 'rb') as f:\n",
    "                ops_obj = pkl.load(f)\n",
    "        else:\n",
    "            ops_obj = diops.PatternSpeed(vars_obj, \\\n",
    "                radii=[0.08, 0.11, 0.15, 0.2, 0.25])\n",
    "        \n",
    "        ops_obj.read(athdf_files, verbose=True, \\\n",
    "                temp_save_path=outfile)\n",
    "        \n",
    "        # save for reuse\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump(ops_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
